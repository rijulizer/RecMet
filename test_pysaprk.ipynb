{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "from RecMet import recmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/02 02:30:00 WARN Utils: Your hostname, machine resolves to a loopback address: 127.0.1.1; using 192.168.31.230 instead (on interface enp0s3)\n",
      "22/03/02 02:30:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/03/02 02:30:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/02 02:30:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('User', 'bigint'), ('Recommended', 'array<string>'), ('Test', 'array<string>'), ('TestLen', 'int')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-------+\n",
      "|User|         Recommended|                Test|TestLen|\n",
      "+----+--------------------+--------------------+-------+\n",
      "|   1|[prod_1, prod_2, ...|[prod_10, prod_4,...|      3|\n",
      "|   2|[prod_10, prod_12...|[prod_1, prod_4, ...|      3|\n",
      "|   3|[prod_11, prod_7,...|[prod_1, prod_2, ...|      9|\n",
      "|   4|[prod_9, prod_12,...|           [prod_12]|      1|\n",
      "+----+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols= ['User','Recommended','Test']\n",
    "data = [[1,['prod_1','prod_2','prod_3','prod_4','prod_5'],['prod_10','prod_4','prod_5']],\n",
    "        [2,['prod_10','prod_12','prod_3','prod_4','prod_15'],['prod_1','prod_4','prod_15']],\n",
    "        [3,['prod_11','prod_7','prod_8','prod_9','prod_15'],['prod_1','prod_2','prod_3','prod_7','prod_9','prod_11','prod_10','prod_4','prod_15']],\n",
    "        [4,['prod_9','prod_12','prod_13','prod_14','prod_15'],['prod_12']]]\n",
    "\n",
    "pdf_rec = pd.DataFrame(data, columns=cols)\n",
    "# pdf_rec.to_csv('./test_data.csv')\n",
    "# pdf_rec = pd.read_csv('./test_data.csv')\n",
    "sdf_rec = spark.createDataFrame(pdf_rec)\n",
    "sdf_rec = sdf_rec.withColumn('TestLen',sf.size(sf.col('Test')))\n",
    "print(sdf_rec.dtypes)\n",
    "sdf_rec.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Initialise variables\n",
    "weight_dict ={\n",
    "    'prod_1':1,\n",
    "    'prod_2':2,\n",
    "    'prod_3':3,\n",
    "    'prod_4':4,\n",
    "    'prod_5':5,\n",
    "    'prod_6':6,\n",
    "    'prod_7':7,\n",
    "    'prod_8':8,\n",
    "    'prod_9':9,\n",
    "    'prod_10':10,\n",
    "    'prod_11':11,\n",
    "    'prod_12':12,\n",
    "    'prod_13':13,\n",
    "    'prod_14':14,\n",
    "    'prod_15':15,\n",
    "    'prod_16':16,\n",
    "    'prod_17':17,\n",
    "    'prod_18':18,\n",
    "}\n",
    "weights =  weight_dict\n",
    "longtail_thresh = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "|User|         Recommended|                Test|TestLen|    AI|  PWAI| ARP|APLT|ACLT|\n",
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "|   1|[prod_1, prod_2, ...|[prod_10, prod_4,...|      3|0.6667|0.4737| 3.0| 0.0| 0.0|\n",
      "|   2|[prod_10, prod_12...|[prod_1, prod_4, ...|      3|0.6667|  0.95| 8.8| 0.6| 3.0|\n",
      "|   3|[prod_11, prod_7,...|[prod_1, prod_2, ...|      9|   0.8|  0.84|10.0| 0.6| 3.0|\n",
      "|   4|[prod_9, prod_12,...|           [prod_12]|      1|   1.0|   1.0|12.6| 1.0| 5.0|\n",
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rm = recmet(weights,longtail_thresh)\n",
    "sdf_rec_metric= sdf_rec.withColumn('AI',rm.AI(sf.col('Recommended'), sf.col('Test')))\\\n",
    "    .withColumn('PWAI',rm.PWAI(sf.col('Recommended'), sf.col('Test')))\\\n",
    "    .withColumn('ARP',rm.ARP(sf.col('Recommended')))\\\n",
    "    .withColumn('APLT',rm.APLT(sf.col('Recommended')))\\\n",
    "    .withColumn('ACLT',rm.ACLT(sf.col('Recommended')))\n",
    "sdf_rec_metric.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67ba6a86c073421af48717667c97b9dd89f212cb6a5befe177e200d138a57b1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
