{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../PythonScripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext ,SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/19 12:49:11 WARN Utils: Your hostname, machine resolves to a loopback address: 127.0.1.1; using 192.168.31.230 instead (on interface enp0s3)\n",
      "22/02/19 12:49:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/02/19 12:49:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/19 12:49:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User            int64\n",
      "Recommended    object\n",
      "Test           object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[prod_1, prod_2, prod_3, prod_4, prod_5]</td>\n",
       "      <td>[prod_10, prod_4, prod_5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[prod_10, prod_12, prod_3, prod_4, prod_15]</td>\n",
       "      <td>[prod_1, prod_4, prod_15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[prod_11, prod_7, prod_8, prod_9, prod_15]</td>\n",
       "      <td>[prod_1, prod_2, prod_3, prod_7, prod_9, prod_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[prod_9, prod_12, prod_13, prod_14, prod_15]</td>\n",
       "      <td>[prod_12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User                                   Recommended  \\\n",
       "0     1      [prod_1, prod_2, prod_3, prod_4, prod_5]   \n",
       "1     2   [prod_10, prod_12, prod_3, prod_4, prod_15]   \n",
       "2     3    [prod_11, prod_7, prod_8, prod_9, prod_15]   \n",
       "3     4  [prod_9, prod_12, prod_13, prod_14, prod_15]   \n",
       "\n",
       "                                                Test  \n",
       "0                          [prod_10, prod_4, prod_5]  \n",
       "1                          [prod_1, prod_4, prod_15]  \n",
       "2  [prod_1, prod_2, prod_3, prod_7, prod_9, prod_...  \n",
       "3                                          [prod_12]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols= ['User','Recommended','Test']\n",
    "data = [[1,['prod_1','prod_2','prod_3','prod_4','prod_5'],['prod_10','prod_4','prod_5']],\n",
    "        [2,['prod_10','prod_12','prod_3','prod_4','prod_15'],['prod_1','prod_4','prod_15']],\n",
    "        [3,['prod_11','prod_7','prod_8','prod_9','prod_15'],['prod_1','prod_2','prod_3','prod_7','prod_9','prod_11','prod_10','prod_4','prod_15']],\n",
    "        [4,['prod_9','prod_12','prod_13','prod_14','prod_15'],['prod_12']]]\n",
    "\n",
    "pdf_rec = pd.DataFrame(data, columns=cols)\n",
    "print(pdf_rec.dtypes)\n",
    "pdf_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('User', 'bigint'), ('Recommended', 'array<string>'), ('Test', 'array<string>')]\n"
     ]
    }
   ],
   "source": [
    "# row1 = [1, ['prod_1','prod_2','prod_3','prod_4','prod_5'], ['prod_1','prod_4','prod_5']]\n",
    "# row2 = [1, ['prod_1','prod_12','prod_13','prod_4','prod_5'], ['prod_11','prod_12','prod_15']]\n",
    "\n",
    "# pdf_rec =pd.read_csv('/home/rijulizer/workspace/RecMet/src/TestData/recommendation_list.csv')\n",
    "sdf_rec = spark.createDataFrame(pdf_rec)\n",
    "# sdf_rec = sdf_rec.withColumn('Recommended',sf.array(sf.col('Recommended')))\\\n",
    "#                  .withColumn('Test',sf.array(sf.col('Test')))\n",
    "print(sdf_rec.dtypes)\n",
    "# sdf_rec.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Initialise variables\n",
    "weight_dict ={\n",
    "    'prod_1':1,\n",
    "    'prod_2':2,\n",
    "    'prod_3':3,\n",
    "    'prod_4':4,\n",
    "    'prod_5':5,\n",
    "    'prod_6':6,\n",
    "    'prod_7':7,\n",
    "    'prod_8':8,\n",
    "    'prod_9':9,\n",
    "    'prod_10':10,\n",
    "    'prod_11':11,\n",
    "    'prod_12':12,\n",
    "    'prod_13':13,\n",
    "    'prod_14':14,\n",
    "    'prod_15':15,\n",
    "    'prod_16':16,\n",
    "    'prod_17':17,\n",
    "    'prod_18':18,\n",
    "}\n",
    "weights =  weight_dict\n",
    "longtail_thresh = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-------+\n",
      "|User|         Recommended|                Test|TestLen|\n",
      "+----+--------------------+--------------------+-------+\n",
      "|   1|[prod_1, prod_2, ...|[prod_10, prod_4,...|      3|\n",
      "|   2|[prod_10, prod_12...|[prod_1, prod_4, ...|      3|\n",
      "|   3|[prod_11, prod_7,...|[prod_1, prod_2, ...|      9|\n",
      "|   4|[prod_9, prod_12,...|           [prod_12]|      1|\n",
      "+----+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_rec = sdf_rec.withColumn('TestLen',sf.size(sf.col('Test')))\n",
    "sdf_rec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # contains all the python codes\n",
    "# import numpy as np\n",
    "\n",
    "# class Metrics:\n",
    "#     def __init__(self, weights, longtail_thresh):\n",
    "#         self.weights = weights\n",
    "#         self.longtail_thresh = longtail_thresh\n",
    "\n",
    "#     # Average Intersection\n",
    "#     def AI(self, recommended, actual):\n",
    "        \n",
    "#         common_num = len(list(set(actual).intersection(set(recommended))))\n",
    "#         AI = round(common_num/ min(len(actual), len(recommended)), 4)\n",
    "        \n",
    "#         return AI\n",
    "\n",
    "#     # Popularity Weighted Avergae Intersection PWAI\n",
    "#     def PWAI(self, recommended, actual):\n",
    "        \n",
    "#         # Set the smaller set as denominator\n",
    "#         if len(actual)<= len(recommended):\n",
    "#             denom_elem = actual\n",
    "#         else:\n",
    "#             denom_elem = recommended\n",
    "        \n",
    "#         common_num_elem = list(set(actual).intersection(set(recommended)))\n",
    "#         # weighted sum of numerator elements\n",
    "#         num = np.array([self.weights[x] for x in common_num_elem]).sum()\n",
    "#         denom = np.array([self.weights[x] for x in denom_elem]).sum()      \n",
    "\n",
    "#         return float(round(num/denom, 4))\n",
    "    \n",
    "#     def ARP(self, recommended):\n",
    "#         item_weights = np.array([self.weights[x] for x in recommended])\n",
    "#         arp = item_weights.mean()\n",
    "\n",
    "#         return float(round(arp, 4))\n",
    "    \n",
    "#     def APLT(self, recommended):\n",
    "#         item_weights = np.array([self.weights[x] for x in recommended])\n",
    "#         avg_longtail_items = (item_weights > self.longtail_thresh).astype(int).mean()\n",
    "        \n",
    "#         return float(round(avg_longtail_items, 4))\n",
    "\n",
    "#     def ACLT(self, recommended):\n",
    "#         item_weights = np.array([self.weights[x] for x in recommended])\n",
    "#         sum_longtail_items = (item_weights > self.longtail_thresh).astype(int).sum()\n",
    "        \n",
    "#         return float(round(sum_longtail_items, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PythonMetrics import Metrics\n",
    "# # met = Metrics(weights, longtail_thresh)\n",
    "# class SuperRecMet(Metrics):\n",
    "#     def __init__(self, weights, longtail_thresh):\n",
    "#         self.weights = weights\n",
    "#         self.longtail_thresh = longtail_thresh\n",
    "#         super().__init__(self.weights, self.longtail_thresh)\n",
    "        \n",
    "        \n",
    "#         met = Metrics(self.weights, self.longtail_thresh)\n",
    "\n",
    "#         # Pyspark AI\n",
    "#         self.AI = sf.udf(lambda x, y: met.AI(x, y), FloatType()) \n",
    "        \n",
    "#         # Pyspark PWAI\n",
    "#         self.PWAI = sf.udf(lambda x, y: met.PWAI(x, y), FloatType())\n",
    "\n",
    "#         # Pyspark ARP\n",
    "#         self.ARP = sf.udf(lambda x: met.ARP(x), FloatType())\n",
    "\n",
    "#         # Pyspark APLT\n",
    "#         self.APLT = sf.udf(lambda x: met.APLT(x), FloatType())\n",
    "\n",
    "#         # Pyspark ACLT\n",
    "#         self.ACLT = sf.udf(lambda x: met.ACLT(x), FloatType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PythonMetrics import Metrics\n",
    "\n",
    "# met = Metrics(weights, longtail_thresh)\n",
    "class RecMet:\n",
    "    def __init__(self, weights, longtail_thresh):\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.longtail_thresh = longtail_thresh\n",
    "        # from PythonMetrics import Metrics\n",
    "        met = Metrics(self.weights, self.longtail_thresh)\n",
    "\n",
    "        # Pyspark AI\n",
    "        self.AI = sf.udf(lambda x, y: met.AI(x, y), FloatType()) \n",
    "        \n",
    "        # Pyspark PWAI\n",
    "        self.PWAI = sf.udf(lambda x, y: met.PWAI(x, y), FloatType())\n",
    "\n",
    "        # Pyspark ARP\n",
    "        self.ARP = sf.udf(lambda x: met.ARP(x), FloatType())\n",
    "\n",
    "        # Pyspark APLT\n",
    "        self.APLT = sf.udf(lambda x: met.APLT(x), FloatType())\n",
    "\n",
    "        # Pyspark ACLT\n",
    "        self.ACLT = sf.udf(lambda x: met.ACLT(x), FloatType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RecMet(weights,longtail_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "|User|         Recommended|                Test|TestLen|    AI|  PWAI| ARP|APLT|ACLT|\n",
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "|   1|[prod_1, prod_2, ...|[prod_10, prod_4,...|      3|0.6667|0.4737| 3.0| 0.0| 0.0|\n",
      "|   2|[prod_10, prod_12...|[prod_1, prod_4, ...|      3|0.6667|  0.95| 8.8| 0.6| 3.0|\n",
      "|   3|[prod_11, prod_7,...|[prod_1, prod_2, ...|      9|   0.8|  0.84|10.0| 0.6| 3.0|\n",
      "|   4|[prod_9, prod_12,...|           [prod_12]|      1|   1.0|   1.0|12.6| 1.0| 5.0|\n",
      "+----+--------------------+--------------------+-------+------+------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_rec_metric= sdf_rec.withColumn('AI',rm.AI(sf.col('Recommended'), sf.col('Test')))\\\n",
    "    .withColumn('PWAI',rm.PWAI(sf.col('Recommended'), sf.col('Test')))\\\n",
    "    .withColumn('ARP',rm.ARP(sf.col('Recommended')))\\\n",
    "    .withColumn('APLT',rm.APLT(sf.col('Recommended')))\\\n",
    "    .withColumn('ACLT',rm.ACLT(sf.col('Recommended')))\n",
    "sdf_rec_metric.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Test</th>\n",
       "      <th>AI</th>\n",
       "      <th>PWAI</th>\n",
       "      <th>ARP</th>\n",
       "      <th>APLT</th>\n",
       "      <th>ACLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[prod_1, prod_2, prod_3, prod_4, prod_5]</td>\n",
       "      <td>[prod_10, prod_4, prod_5]</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[prod_10, prod_12, prod_3, prod_4, prod_15]</td>\n",
       "      <td>[prod_1, prod_4, prod_15]</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[prod_11, prod_7, prod_8, prod_9, prod_15]</td>\n",
       "      <td>[prod_1, prod_2, prod_3, prod_7, prod_9, prod_...</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[prod_9, prod_12, prod_13, prod_14, prod_15]</td>\n",
       "      <td>[prod_12]</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User                                   Recommended  \\\n",
       "0     1      [prod_1, prod_2, prod_3, prod_4, prod_5]   \n",
       "1     2   [prod_10, prod_12, prod_3, prod_4, prod_15]   \n",
       "2     3    [prod_11, prod_7, prod_8, prod_9, prod_15]   \n",
       "3     4  [prod_9, prod_12, prod_13, prod_14, prod_15]   \n",
       "\n",
       "                                                Test      AI    PWAI   ARP  \\\n",
       "0                          [prod_10, prod_4, prod_5]  0.6667  0.4737   3.0   \n",
       "1                          [prod_1, prod_4, prod_15]  0.6667  0.9500   8.8   \n",
       "2  [prod_1, prod_2, prod_3, prod_7, prod_9, prod_...  0.8000  0.8400  10.0   \n",
       "3                                          [prod_12]  1.0000  1.0000  12.6   \n",
       "\n",
       "   APLT  ACLT  \n",
       "0   0.0   0.0  \n",
       "1   0.6   3.0  \n",
       "2   0.6   3.0  \n",
       "3   1.0   5.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_rec_metric.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67ba6a86c073421af48717667c97b9dd89f212cb6a5befe177e200d138a57b1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
